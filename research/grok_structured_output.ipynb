{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75db1a6",
   "metadata": {},
   "source": [
    "# Grok Structured Output Testing\n",
    "\n",
    "Pyndatic AI structured output for grok doesnt work!\n",
    "Grok's native parsing works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49debe9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grok API Key loaded: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import date\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('../envs/.env', override=True)\n",
    "\n",
    "# Verify Grok API key is loaded\n",
    "GROK_API_KEY = os.environ.get(\"GROK_API_KEY\")\n",
    "print(f\"Grok API Key loaded: {GROK_API_KEY is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3035b3d",
   "metadata": {},
   "source": [
    "## Define Pydantic Schemas\n",
    "\n",
    "Define the data models for invoice parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e6d12d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Pydantic schemas defined\n"
     ]
    }
   ],
   "source": [
    "class Currency(str, Enum):\n",
    "    USD = \"USD\"\n",
    "    EUR = \"EUR\"\n",
    "    GBP = \"GBP\"\n",
    "    RUB = \"RUB\"\n",
    "\n",
    "class LineItem(BaseModel):\n",
    "    description: str = Field(description=\"Description of the item or service\")\n",
    "    quantity: int = Field(description=\"Number of units\", ge=1)\n",
    "    unit_price: float = Field(description=\"Price per unit\", ge=0)\n",
    "\n",
    "class Address(BaseModel):\n",
    "    street: str = Field(description=\"Street address\")\n",
    "    city: str = Field(description=\"City\")\n",
    "    postal_code: str = Field(description=\"Postal/ZIP code\")\n",
    "    country: str = Field(description=\"Country\")\n",
    "\n",
    "class Invoice(BaseModel):\n",
    "    vendor_name: str = Field(description=\"Name of the vendor\")\n",
    "    vendor_address: Address = Field(description=\"Vendor's address\")\n",
    "    invoice_number: str = Field(description=\"Unique invoice identifier\")\n",
    "    invoice_date: date = Field(description=\"Date the invoice was issued\")\n",
    "    line_items: List[LineItem] = Field(description=\"List of purchased items/services\")\n",
    "    total_amount: float = Field(description=\"Total amount due\", ge=0)\n",
    "    currency: Currency = Field(description=\"Currency of the invoice\")\n",
    "\n",
    "print(\"‚úì Pydantic schemas defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f78e09",
   "metadata": {},
   "source": [
    "## Initialize Grok Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989cd956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Grok client initialized\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "    api_key=GROK_API_KEY,\n",
    "    base_url=\"https://api.x.ai/v1\",\n",
    ")\n",
    "\n",
    "print(\"‚úì Grok client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abbc820",
   "metadata": {},
   "source": [
    "## Try grok native output structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a048808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Parsed in 4.50s\n",
      "\n",
      "{\n",
      "  \"vendor_name\": \"TechSupply Inc.\",\n",
      "  \"vendor_address\": {\n",
      "    \"street\": \"456 Tech Boulevard\",\n",
      "    \"city\": \"Silicon Valley\",\n",
      "    \"postal_code\": \"94025\",\n",
      "    \"country\": \"USA\"\n",
      "  },\n",
      "  \"invoice_number\": \"TECH-2025-999\",\n",
      "  \"invoice_date\": \"2025-11-10\",\n",
      "  \"line_items\": [\n",
      "    {\n",
      "      \"description\": \"MacBook Pro 16\\\"\",\n",
      "      \"quantity\": 3,\n",
      "      \"unit_price\": 2499.0\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"Magic Mouse\",\n",
      "      \"quantity\": 3,\n",
      "      \"unit_price\": 79.0\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"USB-C Cable (2m)\",\n",
      "      \"quantity\": 10,\n",
      "      \"unit_price\": 19.99\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"Laptop Stand\",\n",
      "      \"quantity\": 3,\n",
      "      \"unit_price\": 49.99\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"External SSD 1TB\",\n",
      "      \"quantity\": 5,\n",
      "      \"unit_price\": 129.99\n",
      "    }\n",
      "  ],\n",
      "  \"total_amount\": 8383.82,\n",
      "  \"currency\": \"USD\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "complex_invoice_text = \"\"\"\n",
    "INVOICE\n",
    "\n",
    "From: TechSupply Inc.\n",
    "Address: 456 Tech Boulevard, Silicon Valley, CA 94025, USA\n",
    "\n",
    "Invoice #: TECH-2025-999\n",
    "Invoice Date: November 10, 2025\n",
    "\n",
    "Line Items:\n",
    "1. MacBook Pro 16\" - Quantity: 3 - Unit Price: $2,499.00\n",
    "2. Magic Mouse - Quantity: 3 - Unit Price: $79.00\n",
    "3. USB-C Cable (2m) - Quantity: 10 - Unit Price: $19.99\n",
    "4. Laptop Stand - Quantity: 3 - Unit Price: $49.99\n",
    "5. External SSD 1TB - Quantity: 5 - Unit Price: $129.99\n",
    "\n",
    "TOTAL: $8,383.82 USD\n",
    "\"\"\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"grok-4-fast-non-reasoning\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract structured invoice data from the provided text. Be precise with numbers and dates.\"},\n",
    "        {\"role\": \"user\", \"content\": complex_invoice_text}\n",
    "    ],\n",
    "    response_format=Invoice,\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "invoice = completion.choices[0].message.parsed\n",
    "print(f\"‚úì Parsed in {elapsed:.2f}s\\n\")\n",
    "print(invoice.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cc132b",
   "metadata": {},
   "source": [
    "## Test 2.1: Stress Test - 50 Runs with structured output Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d5a440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STRESS TEST: 50 RUNS WITH STRUCTURE VALIDATION\n",
      "============================================================\n",
      "\n",
      "Starting stress test: 50 runs...\n",
      "\n",
      "Progress: 10/50 - Last run: 0.61s - Valid: True\n",
      "Progress: 10/50 - Last run: 0.61s - Valid: True\n",
      "Progress: 20/50 - Last run: 0.77s - Valid: True\n",
      "Progress: 20/50 - Last run: 0.77s - Valid: True\n",
      "Progress: 30/50 - Last run: 0.72s - Valid: True\n",
      "Progress: 30/50 - Last run: 0.72s - Valid: True\n",
      "Progress: 40/50 - Last run: 0.73s - Valid: True\n",
      "Progress: 40/50 - Last run: 0.73s - Valid: True\n",
      "Progress: 50/50 - Last run: 0.75s - Valid: True\n",
      "\n",
      "============================================================\n",
      "STRESS TEST RESULTS\n",
      "============================================================\n",
      "\n",
      "üìä Execution Statistics:\n",
      "  Total runs: 50\n",
      "  Successful runs: 50\n",
      "  Failed runs: 0\n",
      "  Success rate: 100.00%\n",
      "\n",
      "‚úÖ Structure Validation:\n",
      "  Valid structures: 50\n",
      "  Invalid structures: 0\n",
      "  Validation rate: 100.00%\n",
      "\n",
      "‚è±Ô∏è  Performance:\n",
      "  Average time: 0.81s\n",
      "  Median time: 0.71s\n",
      "  Min time: 0.61s\n",
      "  Max time: 3.43s\n",
      "  Std deviation: 0.45s\n",
      "\n",
      "============================================================\n",
      "‚úÖ VALIDATION COMPLETE: 100.0% structures valid\n",
      "============================================================\n",
      "Progress: 50/50 - Last run: 0.75s - Valid: True\n",
      "\n",
      "============================================================\n",
      "STRESS TEST RESULTS\n",
      "============================================================\n",
      "\n",
      "üìä Execution Statistics:\n",
      "  Total runs: 50\n",
      "  Successful runs: 50\n",
      "  Failed runs: 0\n",
      "  Success rate: 100.00%\n",
      "\n",
      "‚úÖ Structure Validation:\n",
      "  Valid structures: 50\n",
      "  Invalid structures: 0\n",
      "  Validation rate: 100.00%\n",
      "\n",
      "‚è±Ô∏è  Performance:\n",
      "  Average time: 0.81s\n",
      "  Median time: 0.71s\n",
      "  Min time: 0.61s\n",
      "  Max time: 3.43s\n",
      "  Std deviation: 0.45s\n",
      "\n",
      "============================================================\n",
      "‚úÖ VALIDATION COMPLETE: 100.0% structures valid\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "from typing import Dict, Any\n",
    "from pydantic import ValidationError\n",
    "\n",
    "complex_invoice_text = \"\"\"\n",
    "INVOICE\n",
    "\n",
    "From: TechSupply Inc.\n",
    "Address: 456 Tech Boulevard, Silicon Valley, CA 94025, USA\n",
    "\n",
    "Invoice #: TECH-2025-999\n",
    "Invoice Date: November 10, 2025\n",
    "\n",
    "Line Items:\n",
    "1. MacBook Pro 16\" - Quantity: 3 - Unit Price: $2,499.00\n",
    "2. Magic Mouse - Quantity: 3 - Unit Price: $79.00\n",
    "3. USB-C Cable (2m) - Quantity: 10 - Unit Price: $19.99\n",
    "4. Laptop Stand - Quantity: 3 - Unit Price: $49.99\n",
    "5. External SSD 1TB - Quantity: 5 - Unit Price: $129.99\n",
    "\n",
    "TOTAL: $8,383.82 USD\n",
    "\"\"\"\n",
    "\n",
    "def validate_invoice_structure(invoice: Invoice) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Validate that the invoice structure matches the expected schema.\n",
    "    Returns a dictionary with validation results.\n",
    "    \"\"\"\n",
    "    validation_results = {\n",
    "        \"valid\": True,\n",
    "        \"errors\": [],\n",
    "        \"checks\": {}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Check vendor_name\n",
    "        validation_results[\"checks\"][\"vendor_name\"] = isinstance(invoice.vendor_name, str) and len(invoice.vendor_name) > 0\n",
    "        \n",
    "        # Check vendor_address\n",
    "        addr = invoice.vendor_address\n",
    "        validation_results[\"checks\"][\"vendor_address\"] = all([\n",
    "            isinstance(addr.street, str),\n",
    "            isinstance(addr.city, str),\n",
    "            isinstance(addr.postal_code, str),\n",
    "            isinstance(addr.country, str)\n",
    "        ])\n",
    "        \n",
    "        # Check invoice_number\n",
    "        validation_results[\"checks\"][\"invoice_number\"] = isinstance(invoice.invoice_number, str) and len(invoice.invoice_number) > 0\n",
    "        \n",
    "        # Check invoice_date\n",
    "        validation_results[\"checks\"][\"invoice_date\"] = isinstance(invoice.invoice_date, date)\n",
    "        \n",
    "        # Check line_items\n",
    "        validation_results[\"checks\"][\"line_items_count\"] = len(invoice.line_items) > 0\n",
    "        for i, item in enumerate(invoice.line_items):\n",
    "            validation_results[\"checks\"][f\"line_item_{i}_structure\"] = all([\n",
    "                isinstance(item.description, str),\n",
    "                isinstance(item.quantity, int) and item.quantity >= 1,\n",
    "                isinstance(item.unit_price, float) and item.unit_price >= 0\n",
    "            ])\n",
    "        \n",
    "        # Check total_amount\n",
    "        validation_results[\"checks\"][\"total_amount\"] = isinstance(invoice.total_amount, float) and invoice.total_amount >= 0\n",
    "        \n",
    "        # Check currency\n",
    "        validation_results[\"checks\"][\"currency\"] = isinstance(invoice.currency, Currency)\n",
    "        \n",
    "        # Overall validation\n",
    "        validation_results[\"valid\"] = all(validation_results[\"checks\"].values())\n",
    "        \n",
    "    except Exception as e:\n",
    "        validation_results[\"valid\"] = False\n",
    "        validation_results[\"errors\"].append(str(e))\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "\n",
    "def run_stress_test(num_runs: int = 50) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run the invoice parsing multiple times and validate each result.\n",
    "    \"\"\"\n",
    "    timings = []\n",
    "    validation_results = []\n",
    "    parsing_errors = []\n",
    "    successful_runs = 0\n",
    "    valid_structures = 0\n",
    "    \n",
    "    print(f\"Starting stress test: {num_runs} runs...\\n\")\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            completion = client.beta.chat.completions.parse(\n",
    "                model=\"grok-4-fast-non-reasoning\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Extract structured invoice data from the provided text. Be precise with numbers and dates.\"},\n",
    "                    {\"role\": \"user\", \"content\": complex_invoice_text}\n",
    "                ],\n",
    "                response_format=Invoice,\n",
    "            )\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            timings.append(elapsed)\n",
    "            \n",
    "            # Parse and validate\n",
    "            invoice = completion.choices[0].message.parsed\n",
    "            validation = validate_invoice_structure(invoice)\n",
    "            validation_results.append(validation)\n",
    "            \n",
    "            successful_runs += 1\n",
    "            if validation[\"valid\"]:\n",
    "                valid_structures += 1\n",
    "            \n",
    "            # Print progress every 10 runs\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Progress: {i + 1}/{num_runs} - Last run: {elapsed:.2f}s - Valid: {validation['valid']}\")\n",
    "            \n",
    "        except ValidationError as e:\n",
    "            parsing_errors.append({\n",
    "                \"run\": i + 1,\n",
    "                \"type\": \"ValidationError\",\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "            print(f\"‚úó Run {i + 1}: Validation Error - {e}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            parsing_errors.append({\n",
    "                \"run\": i + 1,\n",
    "                \"type\": \"Exception\",\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "            print(f\"‚úó Run {i + 1}: Error - {e}\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    results = {\n",
    "        \"total_runs\": num_runs,\n",
    "        \"successful_runs\": successful_runs,\n",
    "        \"failed_runs\": len(parsing_errors),\n",
    "        \"valid_structures\": valid_structures,\n",
    "        \"invalid_structures\": successful_runs - valid_structures,\n",
    "        \"success_rate\": (successful_runs / num_runs) * 100,\n",
    "        \"validation_rate\": (valid_structures / successful_runs * 100) if successful_runs > 0 else 0,\n",
    "        \"timings\": {\n",
    "            \"avg\": statistics.mean(timings) if timings else None,\n",
    "            \"min\": min(timings) if timings else None,\n",
    "            \"max\": max(timings) if timings else None,\n",
    "            \"median\": statistics.median(timings) if timings else None,\n",
    "            \"std_dev\": statistics.stdev(timings) if len(timings) > 1 else None,\n",
    "        },\n",
    "        \"all_timings\": timings,\n",
    "        \"parsing_errors\": parsing_errors,\n",
    "        \"validation_details\": validation_results\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Run the stress test\n",
    "print(\"=\"*60)\n",
    "print(\"STRESS TEST: 50 RUNS WITH STRUCTURE VALIDATION\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "stress_results = run_stress_test(num_runs=50)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRESS TEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Execution Statistics:\")\n",
    "print(f\"  Total runs: {stress_results['total_runs']}\")\n",
    "print(f\"  Successful runs: {stress_results['successful_runs']}\")\n",
    "print(f\"  Failed runs: {stress_results['failed_runs']}\")\n",
    "print(f\"  Success rate: {stress_results['success_rate']:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ Structure Validation:\")\n",
    "print(f\"  Valid structures: {stress_results['valid_structures']}\")\n",
    "print(f\"  Invalid structures: {stress_results['invalid_structures']}\")\n",
    "print(f\"  Validation rate: {stress_results['validation_rate']:.2f}%\")\n",
    "\n",
    "if stress_results['timings']['avg']:\n",
    "    print(f\"\\n‚è±Ô∏è  Performance:\")\n",
    "    print(f\"  Average time: {stress_results['timings']['avg']:.2f}s\")\n",
    "    print(f\"  Median time: {stress_results['timings']['median']:.2f}s\")\n",
    "    print(f\"  Min time: {stress_results['timings']['min']:.2f}s\")\n",
    "    print(f\"  Max time: {stress_results['timings']['max']:.2f}s\")\n",
    "    if stress_results['timings']['std_dev']:\n",
    "        print(f\"  Std deviation: {stress_results['timings']['std_dev']:.2f}s\")\n",
    "\n",
    "if stress_results['parsing_errors']:\n",
    "    print(f\"\\n‚ùå Errors ({len(stress_results['parsing_errors'])}):\")\n",
    "    for err in stress_results['parsing_errors'][:5]:  # Show first 5 errors\n",
    "        print(f\"  Run {err['run']}: {err['type']} - {err['error'][:100]}\")\n",
    "    if len(stress_results['parsing_errors']) > 5:\n",
    "        print(f\"  ... and {len(stress_results['parsing_errors']) - 5} more errors\")\n",
    "\n",
    "# Check for any validation failures\n",
    "invalid_validations = [v for v in stress_results['validation_details'] if not v['valid']]\n",
    "if invalid_validations:\n",
    "    print(f\"\\n‚ö†Ô∏è  Invalid Structure Details:\")\n",
    "    for i, v in enumerate(invalid_validations[:3], 1):  # Show first 3\n",
    "        print(f\"\\n  Invalid result #{i}:\")\n",
    "        print(f\"    Failed checks: {[k for k, val in v['checks'].items() if not val]}\")\n",
    "        if v['errors']:\n",
    "            print(f\"    Errors: {v['errors']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ VALIDATION COMPLETE: {stress_results['validation_rate']:.1f}% structures valid\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff06ac",
   "metadata": {},
   "source": [
    "## Trying Native Output in pydantic ai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66db08f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "QUIZ GENERATION STRESS TEST: 50 RUNS WITH VALIDATION\n",
      "============================================================\n",
      "\n",
      "Starting quiz stress test: 50 runs with model grok:grok-4-fast-non-reasoning...\n",
      "\n",
      "‚úó Run 1: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 2: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 3: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 4: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 5: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 6: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 7: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 8: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 9: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 10: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 11: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 12: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 13: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 14: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 15: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 16: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 17: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 18: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 19: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 20: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 21: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 22: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 23: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 24: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 25: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 26: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 27: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 28: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 29: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 30: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 31: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 32: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 33: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 34: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 35: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 36: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 37: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 38: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 39: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 40: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 41: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 42: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 43: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 44: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 45: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 46: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 47: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 48: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 49: Error - Native structured output is not supported by this model.\n",
      "‚úó Run 50: Error - Native structured output is not supported by this model.\n",
      "\n",
      "============================================================\n",
      "QUIZ STRESS TEST RESULTS\n",
      "============================================================\n",
      "\n",
      "üìä Execution Statistics:\n",
      "  Model: grok:grok-4-fast-non-reasoning\n",
      "  Query: Python programming basics\n",
      "  Total runs: 50\n",
      "  Successful runs: 0\n",
      "  Failed runs: 50\n",
      "  Success rate: 0.00%\n",
      "\n",
      "‚úÖ Structure Validation:\n",
      "  Valid structures: 0\n",
      "  Invalid structures: 0\n",
      "  Validation rate: 0.00%\n",
      "\n",
      "‚ùå Errors (50):\n",
      "  Run 1: Exception - Native structured output is not supported by this model.\n",
      "  Run 2: Exception - Native structured output is not supported by this model.\n",
      "  Run 3: Exception - Native structured output is not supported by this model.\n",
      "  Run 4: Exception - Native structured output is not supported by this model.\n",
      "  Run 5: Exception - Native structured output is not supported by this model.\n",
      "  ... and 45 more errors\n",
      "\n",
      "============================================================\n",
      "‚úÖ VALIDATION COMPLETE: 0.0% structures valid\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Literal, Union\n",
    "import httpx\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai import Agent, NativeOutput\n",
    "\n",
    "@dataclass\n",
    "class TestDeps:\n",
    "    \"\"\"Dependencies for the test agent\"\"\"\n",
    "    query: str\n",
    "\n",
    "\n",
    "class QuizItemAnswer(BaseModel):\n",
    "    answer: str = Field(description=\"The answer text\")\n",
    "    explanation: str = Field(description=\"The explanation text\")\n",
    "    correct: bool = Field(description=\"Whether the answer is correct\")\n",
    "\n",
    "\n",
    "class QuizItemTest(BaseModel):\n",
    "    question: str = Field(description=\"The quiz question text\")\n",
    "    answers: list[QuizItemAnswer] = Field(\n",
    "        description=\"4 answers with only one correct\",\n",
    "        min_length=4,\n",
    "        max_length=4\n",
    "    )\n",
    "\n",
    "\n",
    "class TestOutput(BaseModel):\n",
    "    mode: Literal[\"quiz\"] = \"quiz\"\n",
    "    quiz_items: list[QuizItemTest] = Field(\n",
    "        description=\"Array of quiz items\",\n",
    "        min_length=5,\n",
    "        max_length=5\n",
    "    )\n",
    "\n",
    "\n",
    "def validate_quiz_structure(quiz: TestOutput) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Validate that the quiz structure matches the expected schema.\n",
    "    Returns a dictionary with validation results.\n",
    "    \"\"\"\n",
    "    validation_results = {\n",
    "        \"valid\": True,\n",
    "        \"errors\": [],\n",
    "        \"checks\": {}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Check mode\n",
    "        validation_results[\"checks\"][\"mode\"] = quiz.mode == \"quiz\"\n",
    "        \n",
    "        # Check quiz_items count\n",
    "        validation_results[\"checks\"][\"quiz_items_count\"] = len(quiz.quiz_items) == 5\n",
    "        \n",
    "        # Check each quiz item\n",
    "        for i, item in enumerate(quiz.quiz_items):\n",
    "            # Check question\n",
    "            validation_results[\"checks\"][f\"item_{i}_question\"] = isinstance(item.question, str) and len(item.question) > 0\n",
    "            \n",
    "            # Check answers count\n",
    "            validation_results[\"checks\"][f\"item_{i}_answers_count\"] = len(item.answers) == 4\n",
    "            \n",
    "            # Check that exactly one answer is correct\n",
    "            correct_count = sum(1 for ans in item.answers if ans.correct)\n",
    "            validation_results[\"checks\"][f\"item_{i}_one_correct\"] = correct_count == 1\n",
    "            \n",
    "            # Check each answer\n",
    "            for j, answer in enumerate(item.answers):\n",
    "                validation_results[\"checks\"][f\"item_{i}_answer_{j}_text\"] = isinstance(answer.answer, str) and len(answer.answer) > 0\n",
    "                validation_results[\"checks\"][f\"item_{i}_answer_{j}_explanation\"] = isinstance(answer.explanation, str) and len(answer.explanation) > 0\n",
    "                validation_results[\"checks\"][f\"item_{i}_answer_{j}_correct\"] = isinstance(answer.correct, bool)\n",
    "        \n",
    "        # Overall validation\n",
    "        validation_results[\"valid\"] = all(validation_results[\"checks\"].values())\n",
    "        \n",
    "    except Exception as e:\n",
    "        validation_results[\"valid\"] = False\n",
    "        validation_results[\"errors\"].append(str(e))\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "\n",
    "async def run_quiz_stress_test(\n",
    "    model: Union[str, OpenAIChatModel] = \"grok-beta\",\n",
    "    query: str = \"Python programming basics\",\n",
    "    num_runs: int = 50\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run the quiz generation multiple times and validate each result.\n",
    "    \n",
    "    Args:\n",
    "        model: The model to use (default: \"grok-beta\")\n",
    "        query: The topic for quiz generation\n",
    "        num_runs: Number of times to run the test\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with comprehensive test results\n",
    "    \"\"\"\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv('../envs/.env', override=True)\n",
    "\n",
    "    # Verify keys are loaded\n",
    "    TOGETHER_API_KEY = os.environ.get(\"TOGETHER_API_KEY\")\n",
    "    GROK_API_KEY = os.environ.get(\"GROK_API_KEY\")\n",
    "\n",
    "    grok_model = model\n",
    "    \n",
    "    agent = Agent(\n",
    "        model=grok_model,\n",
    "        output_type=NativeOutput(TestOutput),\n",
    "        deps_type=TestDeps,\n",
    "    )\n",
    "    \n",
    "    timings = []\n",
    "    validation_results = []\n",
    "    parsing_errors = []\n",
    "    successful_runs = 0\n",
    "    valid_structures = 0\n",
    "    \n",
    "    model_name = model if isinstance(model, str) else model.model_name\n",
    "    \n",
    "    print(f\"Starting quiz stress test: {num_runs} runs with model {model_name}...\\n\")\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            result = await agent.run(\n",
    "                f\"Generate 5 quiz questions about: {query}\",\n",
    "                deps=TestDeps(query=query)\n",
    "            )\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            timings.append(elapsed)\n",
    "            \n",
    "            # Get output\n",
    "            output = result.output if hasattr(result, 'output') else result.data\n",
    "            \n",
    "            # Validate structure\n",
    "            validation = validate_quiz_structure(output)\n",
    "            validation_results.append(validation)\n",
    "            \n",
    "            successful_runs += 1\n",
    "            if validation[\"valid\"]:\n",
    "                valid_structures += 1\n",
    "            \n",
    "            # Print progress every 10 runs\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Progress: {i + 1}/{num_runs} - Last run: {elapsed:.2f}s - Valid: {validation['valid']}\")\n",
    "            \n",
    "        except ValidationError as e:\n",
    "            parsing_errors.append({\n",
    "                \"run\": i + 1,\n",
    "                \"type\": \"ValidationError\",\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "            print(f\"‚úó Run {i + 1}: Validation Error - {str(e)[:100]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            parsing_errors.append({\n",
    "                \"run\": i + 1,\n",
    "                \"type\": \"Exception\",\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "            print(f\"‚úó Run {i + 1}: Error - {str(e)[:100]}\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    results = {\n",
    "        \"model\": model_name,\n",
    "        \"query\": query,\n",
    "        \"total_runs\": num_runs,\n",
    "        \"successful_runs\": successful_runs,\n",
    "        \"failed_runs\": len(parsing_errors),\n",
    "        \"valid_structures\": valid_structures,\n",
    "        \"invalid_structures\": successful_runs - valid_structures,\n",
    "        \"success_rate\": (successful_runs / num_runs) * 100,\n",
    "        \"validation_rate\": (valid_structures / successful_runs * 100) if successful_runs > 0 else 0,\n",
    "        \"timings\": {\n",
    "            \"avg\": statistics.mean(timings) if timings else None,\n",
    "            \"min\": min(timings) if timings else None,\n",
    "            \"max\": max(timings) if timings else None,\n",
    "            \"median\": statistics.median(timings) if timings else None,\n",
    "            \"std_dev\": statistics.stdev(timings) if len(timings) > 1 else None,\n",
    "        },\n",
    "        \"all_timings\": timings,\n",
    "        \"parsing_errors\": parsing_errors,\n",
    "        \"validation_details\": validation_results\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Run the stress test\n",
    "print(\"=\"*60)\n",
    "print(\"QUIZ GENERATION STRESS TEST: 50 RUNS WITH VALIDATION\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "quiz_stress_results = await run_quiz_stress_test(\n",
    "    model=\"grok:grok-4-fast-non-reasoning\",\n",
    "    query=\"Python programming basics\",\n",
    "    num_runs=50\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUIZ STRESS TEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Execution Statistics:\")\n",
    "print(f\"  Model: {quiz_stress_results['model']}\")\n",
    "print(f\"  Query: {quiz_stress_results['query']}\")\n",
    "print(f\"  Total runs: {quiz_stress_results['total_runs']}\")\n",
    "print(f\"  Successful runs: {quiz_stress_results['successful_runs']}\")\n",
    "print(f\"  Failed runs: {quiz_stress_results['failed_runs']}\")\n",
    "print(f\"  Success rate: {quiz_stress_results['success_rate']:.2f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ Structure Validation:\")\n",
    "print(f\"  Valid structures: {quiz_stress_results['valid_structures']}\")\n",
    "print(f\"  Invalid structures: {quiz_stress_results['invalid_structures']}\")\n",
    "print(f\"  Validation rate: {quiz_stress_results['validation_rate']:.2f}%\")\n",
    "\n",
    "if quiz_stress_results['timings']['avg']:\n",
    "    print(f\"\\n‚è±Ô∏è  Performance:\")\n",
    "    print(f\"  Average time: {quiz_stress_results['timings']['avg']:.2f}s\")\n",
    "    print(f\"  Median time: {quiz_stress_results['timings']['median']:.2f}s\")\n",
    "    print(f\"  Min time: {quiz_stress_results['timings']['min']:.2f}s\")\n",
    "    print(f\"  Max time: {quiz_stress_results['timings']['max']:.2f}s\")\n",
    "    if quiz_stress_results['timings']['std_dev']:\n",
    "        print(f\"  Std deviation: {quiz_stress_results['timings']['std_dev']:.2f}s\")\n",
    "\n",
    "if quiz_stress_results['parsing_errors']:\n",
    "    print(f\"\\n‚ùå Errors ({len(quiz_stress_results['parsing_errors'])}):\")\n",
    "    for err in quiz_stress_results['parsing_errors'][:5]:  # Show first 5 errors\n",
    "        print(f\"  Run {err['run']}: {err['type']} - {err['error'][:100]}\")\n",
    "    if len(quiz_stress_results['parsing_errors']) > 5:\n",
    "        print(f\"  ... and {len(quiz_stress_results['parsing_errors']) - 5} more errors\")\n",
    "\n",
    "# Check for any validation failures\n",
    "quiz_invalid_validations = [v for v in quiz_stress_results['validation_details'] if not v['valid']]\n",
    "if quiz_invalid_validations:\n",
    "    print(f\"\\n‚ö†Ô∏è  Invalid Structure Details:\")\n",
    "    for i, v in enumerate(quiz_invalid_validations[:3], 1):  # Show first 3\n",
    "        print(f\"\\n  Invalid result #{i}:\")\n",
    "        print(f\"    Failed checks: {[k for k, val in v['checks'].items() if not val]}\")\n",
    "        if v['errors']:\n",
    "            print(f\"    Errors: {v['errors']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"‚úÖ VALIDATION COMPLETE: {quiz_stress_results['validation_rate']:.1f}% structures valid\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quizbee-workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
